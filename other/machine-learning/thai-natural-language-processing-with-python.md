# üß§ Thai Natural Language Processing with Python

{% hint style="info" %}
‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ô‡∏Ñ‡∏á‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ Machine Learning ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Text Analysis, Text Mining ‡πÅ‡∏•‡∏∞ Text Analytics ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡πÉ‡∏ä‡πâ Natural Language Processing ( NLP ) ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏≠‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó Speech-to-Text, Text-to-Speech, Speech Recognition, Text Categorization, Text Generation, Machine Translation, Question Answering ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå Text Sentiment ‡πÑ‡∏î‡πâ‡∏≠‡∏µ‡∏Å‡∏î‡πâ‡∏ß‡∏¢
{% endhint %}

## **Thai NLP**

<details>

<summary>Corpus ( corpus )</summary>

‡πÄ‡∏õ‡πá‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÑ‡∏ß‡πâ ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î [Corpus](http://www.arts.chula.ac.th/ling/tnc/) ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏±‡πâ‡∏á Return ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á frozenset

</details>

<details>

<summary>Soundex ( soundex )</summary>

‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ [Word Similarity Matching](https://www.thinkinfi.com/2018/09/word-similarity-matching-using-soundex.html) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏≥ 2 ‡∏Ñ‡∏≥‡∏î‡πâ‡∏ß‡∏¢ Soundex Algorithm ‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡∏Ç‡∏≠‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå Phonetic Type 6 ‡πÅ‡∏ö‡∏ö ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Text Analysis

</details>

<details>

<summary>Spelling ( spell )</summary>

‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ [Spelling Correction](https://www.thinkinfi.com/2019/09/natural-language-processing-using.html) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏™‡∏∞‡∏Å‡∏î‡πÉ‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ Accuracy ‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà 80-90 ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà 10 Word / Second

</details>

<details>

<summary>Summarization ( summarize )</summary>

‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ [Text Summarization](https://stackabuse.com/text-summarization-with-nltk-in-python/) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥ ‡πÇ‡∏î‡∏¢‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ Paragraph ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ Sentence ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥ Word Tokenization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏´‡∏≤ Frequency ‡∏Ç‡∏≠‡∏á Word

</details>

<details>

<summary>Part-of-Speech ( tag )</summary>

‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ [POS Tagging](https://www.thinkinfi.com/2018/10/extract-custom-entity-using-nltk-pos.html) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô Sentence ‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á Word Class ‡∏´‡∏£‡∏∑‡∏≠ Lexical Category ‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏≤ Custom Keyword ‡∏Ç‡∏≠‡∏á Sentence ‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ Engine ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà perceptron ( default ), unigram ‡πÅ‡∏•‡∏∞ artagger

</details>

<details>

<summary>Tokenization ( tokenize )</summary>

‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ [Word Tokenization](https://www.thinkinfi.com/2019/09/natural-language-processing-using.html) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏à‡∏≤‡∏Å Sentence ‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ Engine ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà newmm ( default ), longest, multi\_cut, pyicu, deepcut, tcc ‡πÅ‡∏•‡∏∞ etcc

</details>

<details>

<summary>Transliteration ( transliterate )</summary>

‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ [Romanization, Transliteration, and Transcription](http://www.royin.go.th/wp-content/uploads/royin-ebook/276/FileUpload/758\_6484.pdf) ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏•‡∏∞‡∏ï‡∏¥‡∏ô ‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ Engine ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà royin ( default ) ‡πÅ‡∏•‡∏∞ thai2rom

</details>

<details>

<summary>ULMFit ( ulmfit )</summary>

‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ [Transfer Learning](https://arxiv.org/abs/1801.06146) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á Vocab ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Pretrained Vocab ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ Universal Language Model Fine-tuning for Text Classification ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÑ‡∏î‡πâ‡∏ñ‡∏∂‡∏á 18-24%

</details>

<details>

<summary>Word Vector ( word_vector )</summary>

‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ [Word Embedding](http://nlp.fast.ai/) ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á Vector ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏≥ 2 ‡∏Ñ‡∏≥‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£ Multiplication Combination Objective ‡∏ã‡∏∂‡πà‡∏á‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏Ñ‡∏π‡∏ì‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ Omer Levy & Yoav Goldberg ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡πÑ‡∏î‡πâ List of Word ‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡πà‡∏á Label ‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô Positive ‡πÅ‡∏•‡∏∞ Negative ‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÑ‡∏õ‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡πÉ‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏û‡∏ß‡∏Å

</details>

## **Tokenization Engine**

{% hint style="success" %}
‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ Thai Word Segmentation ‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Dictionary-based ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥ ‡∏ã‡∏∂‡πà‡∏á‡∏Å‡πá‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ Tokenization Engine ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà newmm, longest, multi\_cut, pyicu, deepcut, tcc ‡πÅ‡∏•‡∏∞ etcc
{% endhint %}

## **Get Started**

* ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Virtual Environment

{% code title="C:\>" %}
```
mkvirtualenv thai-nlp
```
{% endcode %}

{% code title="C:\>" %}
```
workon thai-nlp
```
{% endcode %}

* ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Package

{% code title="(thai-nlp) C:\>" %}
```
pip install pythainlp[full]
```
{% endcode %}

* ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå thai\_nlp.py

{% code title="thai_nlp.py" %}
```
from pythainlp.tokenize import word_tokenize

text = "‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏û‡∏±‡∏í‡∏ô‡∏ö‡∏£‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå"
print(word_tokenize(text, engine="newmm")) #['‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏û‡∏±‡∏í‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå']
print(word_tokenize(text, engine="icu")) #['‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô', '‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï', '‡∏û‡∏±‡∏í‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå']
```
{% endcode %}

* ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô thai\_nlp.py

{% code title="" %}
```
python thai_nlp.py
```
{% endcode %}

* ‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥ Word Tokenization

```
['‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏û‡∏±‡∏í‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå']
['‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô', '‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï', '‡∏û‡∏±‡∏í‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå']
```

**‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°** : [https://bit.ly/2mQIeou](https://bit.ly/2mQIeou), [https://bit.ly/2nJyP2h](https://bit.ly/2nJyP2h), [https://bit.ly/2pf9UnN](https://bit.ly/2pf9UnN), [https://bit.ly/2mQqr0y](https://bit.ly/2mQqr0y)
